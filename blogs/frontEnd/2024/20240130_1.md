---
title: 來用 OpenAI 打造企業的客服聊天機器人
date: 2024-01-30
tags:
  - OpenAI
categories:
  - FrontEnd
description: 最近公司在研究怎麼利用開源的 LLM 來開發企業內部的系統，但是很多開源的 LLM 都不如 OpenAI 的東西這麼強大，我這篇文章就先來用 OpenAI 來實現針對 PDF 內容回答的客服機器人，準確率是蠻高的唷!。
meta:
  - name: og:url
    content: https://www.haolit.cc/blogs/frontEnd/2024/20240130_1.html
  - name: og:title
    content: 來用 OpenAI 打造企業的客服聊天機器人
  - name: og:description
    content: 最近公司在研究怎麼利用開源的 LLM 來開發企業內部的系統，但是很多開源的 LLM 都不如 OpenAI 的東西這麼強大，我這篇文章就先來用 OpenAI 來實現針對 PDF 內容回答的客服機器人，準確率是蠻高的唷!。
  - name: og:image
    content: https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDB2MBkVVJB6aCz1tViHPQ.jpeg
---

最近公司在研究怎麼利用開源的 LLM 來開發企業內部的系統，但是很多開源的 LLM 都不如 OpenAI 的東西這麼強大，我這篇文章就先來用 OpenAI 來實現針對 PDF 內容回答的客服機器人，準確率是蠻高的唷!。

<!-- more -->

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDB2MBkVVJB6aCz1tViHPQ.jpeg)

# 來用 OpenAI 打造企業的客服聊天機器人

最近兩周都在研究要如何導入開源模型到本地端使用，避免公司內部資料上傳到 OpenAI 裡面，但是蠻多開源模型的功能也不是那麼健全，索性的我還是先研究 OpenAI 套用相關工具 (LangChain) 的方式，來先理解整個語言模型的應用。

#### 先補充一些觀念

- [LangChain](https://python.langchain.com/docs/get_started/introduction) : AI 開發者的工具，用來連結模型與外部資料，可以快速達到開發的目的。
- [Vector Database](https://myapollo.com.tw/post/vector-databases-simply-explained/)：向量資料庫，針對 AI 的資料進行儲存的一種資料庫，相比傳統的資料儲存模式，取而代之的是一串轉換 (稱之為 Embeddings 或是 transformers) 的資料格式。
- [HuggingFace](https://huggingface.co/)；人工智慧的開源社群平台，使用者可以在上邊發表和共享預訓練模型、資料集和展示檔案等，可以理解為 AI 工程師的 NPM 套件管理工具。

以上三個比較重要的名詞，之後會找時間在解釋，或是讀者自行查找相關資料。

## 申請 [OpenAPI Keys](https://platform.openai.com/apps)

我們這裡應用的是 OpenAI 提供的模型 API，因此需要去申請他的權限 key，會根據 API 呼叫的模型、使用次數等來產生相關的費用。

#### 第一步:

登入後進到這個畫面，我們選擇右邊的 API 選項：

![Imgur](https://i.imgur.com/01mJNEm.png)

#### 第二步:

左邊欄位選擇 API Keys：

![Imgur](https://i.imgur.com/YOqJODc.png)

#### 第三步:

點擊 Create New Secret Key 的按鈕，輸入名稱就可以產生一串 Keys 了，記得要先複製下來，產生完畢後就再也無法複製了。

![Imgur](https://i.imgur.com/tLGnyWo.png)

> 如果後面發生 key 不能使用的情況，大部分就是沒有設定付費的信用卡，到第二步的頁面下面的 setting 選項裡面去設定吧。

## 實作

#### 載入相關套件

因為是開發 AI 相關工具，需要用到的工具其實還蠻多的，以下就先幫我安裝下來吧(用 python 3.11 版本來做開發)

```python
!pip install langchain pypdf sentence_transformers chromadb tiktoken openai langchain-openai
```

#### 建立 `main.py`

在檔案一開始就先把需要的工具都先引入近來

```python
import os
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_openai import OpenAIEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain.text_splitter import TokenTextSplitter
```

#### OpenAI key 放到環境變數中

```python
os.environ["OPENAI_API_KEY"] = "sk-******************************"
```

#### 載入 PDF 檔案方法

這邊用 LangChain 提供的 PDF 載入工具，並且在載入之後把他切分為小小的 chunks，因為 embeddings 的 tokens 長度會有限制。

```python
def load_and_split_documents(filepath="./qa.pdf"):
	loader = filepath.endswith(".pdf") and PyPDFLoader(filepath) or TextLoader(filepath)
	documents = loader.load()
	text_splitter = TokenTextSplitter(chunk_size=300, chunk_overlap=100)
	return text_splitter.split_documents(documents)
```

- 範例為[桃園市政府社會住宅申請辦法](https://housing.tycg.gov.tw/HouseRent/upload/news/2065/%E9%9A%A8%E5%88%B0%E9%9A%A8%E8%BE%A6%E7%94%B3%E8%AB%8B%E9%A0%88%E7%9F%A5-%E5%85%AC%E5%91%8A%E7%89%88_22011311332580267.pdf)
- TokenTextSplitter 這邊用 TokenTextSplitter 來針對文件內容進行分割，也可以用 CharacterTextSplitter，與前者不同的是，後者比較快但是分割的 token 長度可能就不是 LLM 模型可以接受的。

#### 紀錄對話歷史方法

利用 LangChain 提供的 [Memory 模組](https://python.langchain.com/docs/modules/memory/)，其中 [ConversationBufferMemory](https://python.langchain.com/docs/modules/memory/types/buffer) 允許存儲訊息，並將這些對話紀錄存到一個變數中。主要功能是將對話紀錄保存，並隨時提取。

```python
def memory_chat():
	return ConversationBufferMemory(
		memory_key="chat_history",
		return_messages=True,
		output_key="answer")
```

- 還有其他方便使用的 [Memory 方法](https://python.langchain.com/docs/modules/memory/types/)，有不同的參數傳遞、回傳內容，以適應不同的使用情境。
- `print("chat_history:", memory.load_memory_variables({}))` 這樣就可以把對話紀錄給撈出來囉。

#### Prompt Template

在做這種企業 AI 客服機器人的時候，其實很不想要的是使用者直接拿來當作 ChatGPT 使用，就會希望可以只限定回答 PDF 中的內容，這時候就可以用 Promp Template 進行微調。

```python
def get_qa_chain():
  prompt_template = """
		你是社會住宅小幫手，基於以下已知的社會住宅的相關內容，用專業的回答來回應用戶問題，如果發現問題與內容不相關，請說「很抱歉，無法回答你的問題」，
    已知內容:
      {context},
    問題:
      {question}
  """
  return PromptTemplate(template=prompt_template, input_variables=["context", "question"])
```

#### 主程式

以上的方法都定義好了後，接著就可以在主程式中使用囉!這邊我還是把他包成一個方法，晚點再一併呼叫：

```python
def main():
	docs = load_and_split_documents()
	prompt = get_qa_chain()
	memory = memory_chat()

	embeddings = OpenAIEmbeddings()
	vectorstore = Chroma.from_documents(docs, embeddings)

	qa = ConversationalRetrievalChain.from_llm(
		llm = ChatOpenAI(temperature=0),
		retriever = vectorstore.as_retriever(),
		return_source_documents=True,
		verbose=False,
		memory=memory,
		combine_docs_chain_kwargs={"prompt": prompt}
	)
	while True:
		query = input('\nQ: ')
		if not query:
				break
		result = qa({"question": query})
		print("answer:", result["answer"])
```

先來看看主程式會執行的方法:

- embeddings：OpenAI 文字轉成向量格式的方法，這邊是要告訴下一行的向量資料庫，之後丟進去的資料都要透過這個方法去 embeddings，之後在資料庫做搜尋的時候，也是一樣要先透過這個方法去轉換文字後再做搜尋。
- vectorstore: 這邊使用的向量資料庫是 chromaDB，比較適合小型的向量資料儲存，並且資料是存在暫存記憶體，程式結束後會清空(也可以做 Persistent)。
- ConversationalRetrievalChain: 這邊就是最主要的，在與 LLM 對話的時候，會優先根據使用的問題跟對話紀錄來針對文件進行搜索，同時也會優先回答文件內容。

這三個方法其實都可以換成其他模型或是資料庫，例如 embeddings 的方式就有很多種，`sentence-transformers/all-MiniLM-L6-v2` 就是很多人常用的，要注意的是每個 embeddings 模型，他的 tokens 長度限制，在切分對應的 doc 長度時要注意。

vectorstore，同時也可以換成[其他向量資料庫](https://python.langchain.com/docs/integrations/vectorstores/)，使用方式裡面也有說明。

ConversationalRetrievalChain 的第一個參數可以指定其他的語言模型。

#### 執行

```python
if __name__ == "__main__":
  main()
```

以下是測試內回答的內容：

![Imgur](https://i.imgur.com/QOl6KMF.png)

## 結論

用聊天的方式，快速讓使用者可以查找到需要的資料，LLM 出現以及 LangChain 的應用，真的是開發者的福音。同時，可以透過 FastAPI 以達到更多種應用方式。公司目前正在想辦法透過 Fine Turning 或是 Prompt template 的方式，調整成內部的工具系統，最大的目標是把 LLM、Embeddings 等方法都換成開源模型。

##### 參考資料

1. [ChatPDF](https://www.chatpdf.com/)
2. [一篇文章搞懂 LangChain](https://www.readfog.com/a/1706407494707941376)
3. [How to Chat With Multiple PDF Files](https://www.youtube.com/watch?v=Ix9WIZpArm0)
4. [让 Langchain 与你的数据对话(一)：数据加载与分割](https://zhuanlan.zhihu.com/p/644938147)
5. [全端 LLM 應用開發](https://ithelp.ithome.com.tw/users/20120030/ironman/7039)
